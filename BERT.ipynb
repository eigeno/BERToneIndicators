{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdPRp4q7iisZ"
      },
      "source": [
        "# TODO\n",
        "- Data Analysis\n",
        "  <!-- - distribution -->\n",
        "  - visualization\n",
        "- Preprocessing\n",
        "  - cleaning the labels\n",
        "  <!-- - Tokenization -->\n",
        "  - Data Load, class balancing?, k-cross fold validation?\n",
        "- Model\n",
        "  <!-- - BERT from pretrained -->\n",
        "  <!-- - optizer, scheduler, criteria etc. -->\n",
        "<!-- - Training Procedure -->\n",
        "- Testing\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G552kmZMHZth",
        "outputId": "76feea13-cf49-4cf2-9f5d-8c9020edabce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.0 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 596 kB 43.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.6 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 77 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.50.tar.gz (880 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 880 kB 39.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Collecting click==8.0\n",
            "  Downloading click-8.0.0-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 96 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.50-py3-none-any.whl size=895166 sha256=59e01e590cb384af1ce27eac751ede5636fb802a697890a11d5d30dd0eea77e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/72/54/519f0d5143cc6c73fa3297509123c86fc8586a7fdea8d25311\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: pyyaml, click, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.0.0 which is incompatible.\u001b[0m\n",
            "Successfully installed click-8.0.0 huggingface-hub-0.5.1 pyyaml-6.0 sacremoses-0.0.50 tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 175 kB 5.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: emoji\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=8d570c3c04a7a16617654c6aa3652b1a31729d87c6bcc5564f51a48795ad6ac8\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built emoji\n",
            "Installing collected packages: emoji\n",
            "Successfully installed emoji-1.7.0\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 981 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=651158dea0dc1e0d5afed87fa6fb4fa4b72b89d7831d7b3bbf98d3928564c131\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install emoji\n",
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKIWwCsUigIp",
        "outputId": "9d6bb94f-52a8-4413-b0fc-f3c9fce6a58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 1.21.6\n",
            "pandas 1.3.5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "print('numpy', np.__version__)\n",
        "import pandas as pd\n",
        "print('pandas', pd.__version__)\n",
        "from langdetect import detect\n",
        "import random\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
        "\n",
        "from transformers import AutoTokenizer, BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "from tqdm import tqdm #progress bar\n",
        "\n",
        "# Evaluation\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dstqlyfGj7cL",
        "outputId": "33beffa1-24f0-41d9-b5ee-6390bec89bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oxjZHmBgkSNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d6815f-5992-4f79-8e23-7aca1e77c242"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/16W2OVxf4pSh-3dRxed_aDRKcUuYcKpsj/Twitter\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/My Drive/Twitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mpL5JTg4G1Gn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dbO0815G72P",
        "outputId": "aca66921-a2df-4ec1-b6d5-85457c7b1c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device count: 1\n",
            "Using device: cuda\n",
            "Tesla K80\n",
            "_CudaDeviceProperties(name='Tesla K80', major=3, minor=7, total_memory=11441MB, multi_processor_count=13)\n",
            "Memory Usage:\n",
            "Allocated: 0.0 GB\n",
            "Cached:    0.0 GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/cuda/memory.py:386: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print('Device count:', cuda.device_count())\n",
        "print('Using device:', device)\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))\n",
        "    print(torch.cuda.get_device_properties(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIAM_8w-jyVJ"
      },
      "source": [
        "# Load tweets from file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "KTbKkIxKj23n",
        "outputId": "d1bbb0b3-84dc-44ae-d83b-4460a4bcbe99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'srs', 'nbh', 'hyp', 'pos', 'neg'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                  text  srs  \\\n",
              "tid                                                                           \n",
              "1491924924386230287                RT @malewifealtair: @sobokify /srs.    1   \n",
              "1491924858493620227        i just swallowed a small gemstone /srs /pos    1   \n",
              "1491924846242152457  @bonsorlol no bc it genuinely had great themes...    0   \n",
              "1491924808476422144  registering for classes /neg üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´ i am so...    0   \n",
              "1491924691925311489  I found out about fnf a week or two after it c...    1   \n",
              "...                                                                ...  ...   \n",
              "1495361726807560194  always show up on my tl /pos but were not clos...    0   \n",
              "1495361724601417729                                       screams /neg    0   \n",
              "1495361646067392520            @walterhillerska i hate gay people /srs    1   \n",
              "1495361617466621955                are u comfy with this user ?? /srs.    1   \n",
              "1495361430178074626        damn he actually did kiss the ice im üò≠ /pos    0   \n",
              "\n",
              "                     nbh  hyp  pos  neg  \n",
              "tid                                      \n",
              "1491924924386230287    0    0    0    0  \n",
              "1491924858493620227    0    0    1    0  \n",
              "1491924846242152457    0    0    1    0  \n",
              "1491924808476422144    0    0    0    1  \n",
              "1491924691925311489    0    0    0    0  \n",
              "...                  ...  ...  ...  ...  \n",
              "1495361726807560194    0    0    1    0  \n",
              "1495361724601417729    0    0    0    1  \n",
              "1495361646067392520    0    0    0    0  \n",
              "1495361617466621955    0    0    0    0  \n",
              "1495361430178074626    0    0    1    0  \n",
              "\n",
              "[149847 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46357bf2-8cec-4dfb-95b9-fa0412327b33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>srs</th>\n",
              "      <th>nbh</th>\n",
              "      <th>hyp</th>\n",
              "      <th>pos</th>\n",
              "      <th>neg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tid</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1491924924386230287</th>\n",
              "      <td>RT @malewifealtair: @sobokify /srs.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491924858493620227</th>\n",
              "      <td>i just swallowed a small gemstone /srs /pos</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491924846242152457</th>\n",
              "      <td>@bonsorlol no bc it genuinely had great themes...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491924808476422144</th>\n",
              "      <td>registering for classes /neg üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´ i am so...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1491924691925311489</th>\n",
              "      <td>I found out about fnf a week or two after it c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495361726807560194</th>\n",
              "      <td>always show up on my tl /pos but were not clos...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495361724601417729</th>\n",
              "      <td>screams /neg</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495361646067392520</th>\n",
              "      <td>@walterhillerska i hate gay people /srs</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495361617466621955</th>\n",
              "      <td>are u comfy with this user ?? /srs.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1495361430178074626</th>\n",
              "      <td>damn he actually did kiss the ice im üò≠ /pos</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>149847 rows √ó 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46357bf2-8cec-4dfb-95b9-fa0412327b33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46357bf2-8cec-4dfb-95b9-fa0412327b33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46357bf2-8cec-4dfb-95b9-fa0412327b33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data = pd.read_csv('all_tweets_english.tsv', delimiter='\\t', index_col=0, on_bad_lines='skip')\n",
        "print(data.columns)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wNyLfih3mdQf"
      },
      "outputs": [],
      "source": [
        "# sum_data = data['srs']+data['nbh']+data['hyp']+data['pos']+data['neg']\n",
        "# count = 0\n",
        "# for i, c in enumerate(sum_data):\n",
        "#   if c >1:\n",
        "#     print(i, c, data['text'][i])\n",
        "#     count +=1\n",
        "# print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNaoV7zTpT-v",
        "outputId": "bb81d3e2-0324-46d8-edd2-944e1e73c027"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The rate of tweets with more than 1 tags: 0.01030066815144766\n"
          ]
        }
      ],
      "source": [
        "#rate of more than 1 label\n",
        "print('The rate of tweets with more than 1 tags:', 111/10776)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGdHt76VG-yf"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDrSrgh9W3Rv",
        "outputId": "770bfe11-2eab-45a0-ebd1-34e96ea856ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                  text  srs  \\\n",
            "tid                                                                           \n",
            "1491924924386230287                RT @malewifealtair: @sobokify /srs.    1   \n",
            "1491924858493620227        i just swallowed a small gemstone /srs /pos    1   \n",
            "1491924846242152457  @bonsorlol no bc it genuinely had great themes...    0   \n",
            "1491924808476422144  registering for classes /neg üòµ‚Äçüí´üòµ‚Äçüí´üòµ‚Äçüí´ i am so...    0   \n",
            "1491924691925311489  I found out about fnf a week or two after it c...    1   \n",
            "...                                                                ...  ...   \n",
            "1495361726807560194  always show up on my tl /pos but were not clos...    0   \n",
            "1495361724601417729                                       screams /neg    0   \n",
            "1495361646067392520            @walterhillerska i hate gay people /srs    1   \n",
            "1495361617466621955                are u comfy with this user ?? /srs.    1   \n",
            "1495361430178074626        damn he actually did kiss the ice im üò≠ /pos    0   \n",
            "\n",
            "                     nbh  hyp  pos  neg  \n",
            "tid                                      \n",
            "1491924924386230287    0    0    0    0  \n",
            "1491924858493620227    0    0    1    0  \n",
            "1491924846242152457    0    0    1    0  \n",
            "1491924808476422144    0    0    0    1  \n",
            "1491924691925311489    0    0    0    0  \n",
            "...                  ...  ...  ...  ...  \n",
            "1495361726807560194    0    0    1    0  \n",
            "1495361724601417729    0    0    0    1  \n",
            "1495361646067392520    0    0    0    0  \n",
            "1495361617466621955    0    0    0    0  \n",
            "1495361430178074626    0    0    1    0  \n",
            "\n",
            "[149829 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "contain_values = data[data['text'].str.contains('/srs|/nbh|/hyp|/pos|/neg')]\n",
        "contain_values[\"text\"] = contain_values[\"text\"].str.replace(r'\\s*https?://\\S+(\\s+|$)', ' ').str.strip()\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "labeled = contain_values\n",
        "labeled[\"srs\"] = np.where(labeled[\"text\"].str.contains('/srs'), 1, 0)\n",
        "labeled[\"nbh\"] = np.where(labeled[\"text\"].str.contains('/nbh'), 1, 0)\n",
        "labeled[\"hyp\"] = np.where(labeled[\"text\"].str.contains('/hyp'), 1, 0)\n",
        "labeled[\"pos\"] = np.where(labeled[\"text\"].str.contains('/pos'), 1, 0)\n",
        "labeled[\"neg\"] = np.where(labeled[\"text\"].str.contains('/neg'), 1, 0)\n",
        "data = labeled\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncomment and run the next cell if your dataset is not filtered for only english tweets containing tone indictors. Otherwise if your data is clean, skip it "
      ],
      "metadata": {
        "id": "Mjft-Hn_oKcL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y_4pNUv4hwgX",
        "outputId": "360cf2cd-4904-4a61-ec5c-4ef185228921"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndf_new = data[data.text.apply(detect2).eq('en')]\\nprint(df_new)\\ndata = df_new\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# The fastest runtime comes from applying this function to the entire df\n",
        "\"\"\"\n",
        "def detect2(row):\n",
        "  res = \"error\"\n",
        "  try:\n",
        "    res = detect(row)\n",
        "    return res\n",
        "  except:\n",
        "    return res\n",
        "\"\"\"\n",
        "\n",
        "# Example Run:\n",
        "'''\n",
        "df = pd.read_csv(\"in.tsv.tsv\",sep='\\t')\n",
        "contain_values = df[df['text'].str.contains('/srs|/nbh|/hyp|/pos|/neg')]\n",
        "contain_values[\"text\"] = contain_values[\"text\"].str.replace(r'\\s*https?://\\S+(\\s+|$)', ' ').str.strip()\n",
        "df_new = contain_values[contain_values.text.apply(detect2).eq('en')]\n",
        "print(df_new)\n",
        "df_new.to_csv('out.tsv', sep=\"\\t\")\n",
        "'''\n",
        "\n",
        "#First we exclude rows that don't have the tags, then exclude rows that have URLs\n",
        "#Use detect2 for the final frame and convert to tsv\n",
        "\n",
        "'''\n",
        "df_new = data[data.text.apply(detect2).eq('en')]\n",
        "print(df_new)\n",
        "data = df_new\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nJA7_MeZzY5u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "19b28aec-2c14-4bf5-a3c1-27cf7c1d63f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nprint(df_new)\\ndf_new.to_csv(\\'all_tweets_english.tsv\\', sep=\"\\t\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# sava cleaned data \n",
        "'''\n",
        "print(df_new)\n",
        "df_new.to_csv('all_tweets_english.tsv', sep=\"\\t\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRLrd4boHoDT"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lPPRZDZHyvE",
        "outputId": "3b75fbf4-1207-4dfb-e8b0-a25ebd833f7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 147807 entries, 0 to 147806\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   text    147807 non-null  object\n",
            " 1   srs     147807 non-null  int64 \n",
            " 2   nbh     147807 non-null  int64 \n",
            " 3   hyp     147807 non-null  int64 \n",
            " 4   pos     147807 non-null  int64 \n",
            " 5   neg     147807 non-null  int64 \n",
            "dtypes: int64(5), object(1)\n",
            "memory usage: 6.8+ MB\n",
            "None\n",
            "srs    51329\n",
            "nbh     4080\n",
            "hyp      105\n",
            "pos    78147\n",
            "neg    14146\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#remove the tweets with more than 1 tag\n",
        "tones = ['srs', 'nbh', 'hyp', 'pos', 'neg']\n",
        "\n",
        "filter = data[tones].sum(axis=1)==1\n",
        "data = data[filter].reset_index(drop=True)\n",
        "print(data.info())\n",
        "print(data[tones].sum(axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PpHgC4yhUXls",
        "outputId": "e91070ad-873f-4a16-adad-ddb832d4438c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-28-1b912378bc2e>\", line 1, in <module>\n",
            "    data['tag']=data[tones].apply(lambda row: row[row==1].index[0], axis=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\", line 8740, in apply\n",
            "    return op.apply()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\", line 688, in apply\n",
            "    return self.apply_standard()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\", line 812, in apply_standard\n",
            "    results, res_index = self.apply_series_generator()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\", line 828, in apply_series_generator\n",
            "    results[i] = self.f(v)\n",
            "  File \"<ipython-input-28-1b912378bc2e>\", line 1, in <lambda>\n",
            "    data['tag']=data[tones].apply(lambda row: row[row==1].index[0], axis=1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\", line 962, in __getitem__\n",
            "    key = check_bool_indexer(self.index, key)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\", line 2384, in check_bool_indexer\n",
            "    if isinstance(key, ABCSeries) and not key.index.equals(index):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\", line 4728, in equals\n",
            "    def equals(self, other: Any) -> bool:\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "# this can take 1-2 minutes to run\n",
        "data['tag']=data[tones].apply(lambda row: row[row==1].index[0], axis=1)\n",
        "\n",
        "label2ind = {tag: tones.index(tag) for tag in tones}\n",
        "tags_token= data['tag'].apply(lambda x: label2ind[x])\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHVO7EHvUpQz"
      },
      "outputs": [],
      "source": [
        "# replace all the tags in texts with [unknown token]\n",
        "data['text'] = data['text'].str.replace('/srs','TONE_INDICATOR')\n",
        "data['text'] = data['text'].str.replace('/nbh','TONE_INDICATOR')\n",
        "data['text'] = data['text'].str.replace('/pos','TONE_INDICATOR')\n",
        "data['text'] = data['text'].str.replace('/hyp','TONE_INDICATOR')\n",
        "data['text'] = data['text'].str.replace('/neg','TONE_INDICATOR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "212b508689a64a599a92941999c77105",
            "3aa5043b136545ec82f1404e6c00c499",
            "be8ce9b6d0994e73a84a6086d8a3f991",
            "7c0761be0674443a9056f38eea06e9b4",
            "bcc84f2b863d45268937c65e75cfcf1d",
            "1f388cfa85e84b2c85fa85c5970ccc50",
            "91e97afea50f4a00a2254c7440f72de4",
            "4db62856ce55474f921deb4fb26bf032",
            "31c04396a79f4a76b1b3f7a4ae5a49ca",
            "6133a00a4e6b47e1ac773dd5f2713558",
            "b4ec17e6b954467f9da013ca6b6c574f",
            "c4d7b2c977c642ffa73faf05c8174246",
            "884cbdcd05f240cdb768dbe9fbab5e36",
            "f16a0583627b4c6ea422514296428f17",
            "39160144849c4a98a825eb698f63d145",
            "bf7b57bcdf0b404fa79d4d2e344c9769",
            "448b5aa17256467e8bffbbe2d74479a1",
            "2acbe1af1276422ca85312531ed9c07e",
            "4991558fc0184d0084008f6a1bf4ba3d",
            "4c58f6be0e8247839b540ac3a4177747",
            "07c6b11bf83943bc8c90ed3b86b3c4e1",
            "c667f575d4064a7997f43c98298491bf",
            "6eb002759658459fb9a2b892c1d7faf7",
            "ff1d891d6b4641fcab1cf1ad441e6756",
            "8ba157ac6fb2449b9d49fd477af80e6d",
            "43f3573b30144c949755d57dad812d54",
            "b0c5a573297541c49deb697de0d96c4c",
            "9550b6eef4e14364b19aeeda1c011881",
            "2f7de119890a46c489400a6b7dcd1698",
            "1acdc8f5c56044f5ac7722dcc087b28c",
            "d8f8dd58b7a44c4f8d4eb287a0de88c8",
            "9f4409c4d5474720a7d3f26168acf87c",
            "0ebe993975884742b510817c236cbc5d"
          ]
        },
        "id": "-cPlTjd8VU0Z",
        "outputId": "fbf17a36-7e9e-4437-ff93-63a2a2859227"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/558 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "212b508689a64a599a92941999c77105"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/824k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4d7b2c977c642ffa73faf05c8174246"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eb002759658459fb9a2b892c1d7faf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length before new token 64001\n",
            "length after new token 64001\n",
            "im going to cry we didnt look at eachother or even fucking look at eachother :// TONE_INDICATOR\n",
            " Original:  im going to cry we didnt look at eachother or even fucking look at eachother :// TONE_INDICATOR\n",
            "Tokenized:  ['im', 'going', 'to', 'cry', 'we', 'didnt', 'look', 'at', 'eachother', 'or', 'even', 'fucking', 'look', 'at', 'eachother', ':@@', '/@@', '/', 'TON@@', 'E_@@', 'IND@@', 'IC@@', 'ATOR']\n",
            "Token IDs:  [199, 117, 9, 866, 54, 1403, 184, 35, 9317, 72, 132, 309, 184, 35, 9317, 1043, 2603, 75, 16457, 35637, 16065, 2965, 22679]\n"
          ]
        }
      ],
      "source": [
        "#tokenize sentences\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "print(\"length before new token\", len(tokenizer))\n",
        "#tokenizer.add_tokens([\"TONE_INDICATOR\"])\n",
        "print(\"length after new token\", len(tokenizer))\n",
        "\n",
        "tweets = data['text']\n",
        "print(tweets[23])\n",
        "print(' Original: ', tweets[23])\n",
        "print('Tokenized: ', tokenizer.tokenize(tweets[23]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(tweets[23])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PvwjvyDdOmj",
        "outputId": "cb648c0c-976c-47dd-d6a8-a7cc098dd2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (165 > 128). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  284\n"
          ]
        }
      ],
      "source": [
        "#get max length of sentence token\n",
        "max_len = 0\n",
        "count = 0\n",
        "\n",
        "for twt in tweets:\n",
        "    input_ids = tokenizer.encode(twt, add_special_tokens=True) #add `[CLS]` and `[SEP]` tokens.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "# tokenizer.max_len_sentences_pair, tokenizer.max_len_single_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk9sqfxDddKV",
        "outputId": "a97c918c-f1e6-49c0-a6db-f347a8ff1611"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2269: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  RT @malewifealtair: @sobokify TONE_INDICATOR.\n",
            "Token IDs: tensor([    0,   246,  5238,  4151,   515,  2583, 15590,   836,  1257,  1784,\n",
            "           22,  5238,  2266,  1384,   409, 16044, 16457, 35637, 16065,  2965,\n",
            "         3368,  3447,     4,     2,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "            1,     1,     1,     1])\n"
          ]
        }
      ],
      "source": [
        "# encode tokenized sentences \n",
        "\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "for twt in tweets:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        twt,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 124,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "        \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(tags_token)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', tweets[0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gHTVvo1gHxU"
      },
      "source": [
        "# Train/test split, dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCxaxtLRgG7_",
        "outputId": "d3c09c0e-0af6-4d5e-8d0f-88c2e969c19e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "133,026 training samples\n",
            "14,781 validation samples\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3i3g145oMQ2"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRMi6UOkHJ_I"
      },
      "source": [
        "# Model\n",
        "model architecture:\n",
        "pretrained-BERT + classifier layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoUBracGpnr2"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "    def __init__(self, bert, output_size):\n",
        "        super(BERT_Arch, self).__init__()\n",
        "\n",
        "        self.bert = bert\n",
        "        \n",
        "        self.fc1 = nn.Linear(768,512)\n",
        "        self.fc2 = nn.Linear(512, 128)\n",
        "        self.fc3 = nn.Linear(128, output_size)\n",
        "        \n",
        "        #activation functions\n",
        "        self.dropout1 = nn.Dropout(0.1)\n",
        "        self.dropout2 = nn.Dropout(0.1)\n",
        "        self.relu1 =  nn.ReLU()\n",
        "        self.relu2 =  nn.ReLU()\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        \n",
        "    def forward(self, sent_id, mask):\n",
        "        \n",
        "        bert_out = self.bert(sent_id, attention_mask=mask).pooler_output #(batch_size, hidden_size)\n",
        "      \n",
        "        x = self.fc1(bert_out)\n",
        "        x = self.relu1(x)                   \n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)             \n",
        "        x = self.dropout2(x)\n",
        "                     \n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "                     \n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRMrAD7xVUu1"
      },
      "outputs": [],
      "source": [
        "!CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "4147b6dfab1b4aa1ad347f1861be2cc8",
            "cdccf6ee1aee482e8f7e84dc128ccdc5",
            "f574c001f4784d5da0c827cfa9882578",
            "3ade69600e0440a0b2544234f7bdd54f",
            "a5d53803cdf8414f930f80dbb4c012a3",
            "2741349cf89a4778a5e9330c27e95299",
            "91a808ac69404806b3708ca4e93dcf45",
            "7c82c16b68684f6eae6a0e97d950e26d",
            "cab65a29d672448881a6e3026e457713",
            "d8a0a8839c76423ea6b82eae16dd16ae",
            "2f745a199bce43a4af95be9bd72622b1"
          ]
        },
        "id": "TA68md-2ouhn",
        "outputId": "08a8c44c-ade7-4f2e-829f-67586db49721"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/517M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4147b6dfab1b4aa1ad347f1861be2cc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at vinai/bertweet-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(64001, 768, padding_idx=1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from transformers import AutoModel, BertModel, AdamW, BertConfig\n",
        "#load from pretrained\n",
        "#bert_pretrained = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert_pretrained = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "bert_pretrained.resize_token_embeddings(len(tokenizer)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7H1TjGYYFpf",
        "outputId": "ea873702-8a21-4117-bd33-fb90fecaf7fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT_Arch(\n",
            "  (bert): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=5, bias=True)\n",
            "  (dropout1): Dropout(p=0.1, inplace=False)\n",
            "  (dropout2): Dropout(p=0.1, inplace=False)\n",
            "  (relu1): ReLU()\n",
            "  (relu2): ReLU()\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = BERT_Arch(bert_pretrained, output_size=len(tones))\n",
        "\n",
        "#print(model.embeddings.word_embeddings.weight[-1, :])\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8\n",
        "                )\n",
        "\n",
        "model = model.to(device)\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUAs880MqS55"
      },
      "source": [
        "### Accuracy Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEHbZdztqcfR"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    \n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgPf6qY7qfgm"
      },
      "source": [
        "## Training/validating wrapper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xM7Dq7VaqezE"
      },
      "outputs": [],
      "source": [
        "def training(train_dataloader, model):\n",
        "    \n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "    total_train_accuracy = 0\n",
        "    \n",
        "    model.train() \n",
        "\n",
        "    loop = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
        "    \n",
        "    for step, batch in loop:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        optimizer.zero_grad() \n",
        "\n",
        "        ### forward pass ###\n",
        "        b_train_pred = model(b_input_ids, mask=b_input_mask)\n",
        "        \n",
        "        loss = criterion(b_train_pred, b_labels)\n",
        "        accuracy = multi_acc(b_train_pred, b_labels)\n",
        "        \n",
        "        total_train_loss += loss.item() * b_input_ids.shape[0]\n",
        "        total_train_accuracy += accuracy.item()* b_input_ids.shape[0]\n",
        "        \n",
        "        ### backward pass ###\n",
        "        loss.backward()\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "        loop.set_postfix(loss=loss.item(), acc=accuracy.item())\n",
        "        \n",
        "    avg_train_accuracy = total_train_accuracy / train_dataloader.dataset.__len__()\n",
        "    avg_train_loss = total_train_loss / train_dataloader.dataset.__len__()        \n",
        "    training_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_train_accuracy))\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "    \n",
        "\n",
        "    return avg_train_accuracy, avg_train_loss, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN8Dpj5UrccB"
      },
      "outputs": [],
      "source": [
        "def validating(validation_dataloader, model):\n",
        "    '''return validation accuracy, loss and time'''\n",
        "\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in tqdm(validation_dataloader):\n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            b_train_pred = model(b_input_ids, mask=b_input_mask)\n",
        "        \n",
        "            loss = criterion(b_train_pred, b_labels)\n",
        "            accuracy = multi_acc(b_train_pred, b_labels)\n",
        "            \n",
        "        total_eval_loss += loss.item()*b_input_ids.shape[0]\n",
        "        total_eval_accuracy += accuracy.item()*b_input_ids.shape[0]\n",
        "     \n",
        "    \n",
        "    avg_val_accuracy = total_eval_accuracy / validation_dataloader.dataset.__len__()\n",
        "    avg_val_loss = total_eval_loss / validation_dataloader.dataset.__len__()\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    \n",
        "    return avg_val_accuracy, avg_val_loss, validation_time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIlUJutprwOF"
      },
      "source": [
        "# Main training procedure\n",
        "reccomended to run on GPU if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "ujbqaANzr1MR",
        "outputId": "e38bbca2-717d-41fa-dd97-0fc9049705d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nseed_val = 42\\n\\nrandom.seed(seed_val)\\nnp.random.seed(seed_val)\\ntorch.manual_seed(seed_val)\\ntorch.cuda.manual_seed_all(seed_val)\\n\\ntraining_stats = []\\n\\nepochs = 10\\n\\ntotal_t0 = time.time() \\n\\nfor epoch_i in range(0, epochs):\\n    print(\"\")\\n    print(\\'======== Epoch {:} / {:} ========\\'.format(epoch_i + 1, epochs))\\n    ## =================== Training =================== ##\\n    avg_train_accuracy, avg_train_loss, training_time = training(train_dataloader, model)\\n        \\n    ## =================== Validation =================== ##\\n    avg_val_accuracy, avg_val_loss, validation_time = validating(validation_dataloader, model)\\n    \\n    # Record all statistics from this epoch.\\n    training_stats.append(\\n        {\\n            \\'epoch\\': epoch_i + 1,\\n            \\'Training Loss\\': avg_train_loss,\\n            \\'Training Accur.\\': avg_train_accuracy,\\n            \\'Valid. Loss\\': avg_val_loss,\\n            \\'Valid. Accur.\\': avg_val_accuracy,\\n            \\'Training Time\\': training_time,\\n            \\'Validation Time\\': validation_time,\\n        }\\n    )\\n    \\n    #save model\\ntorch.save({\\n      \\'epoch\\': epoch_i+1,\\n      \\'model_state_dict\\': model.state_dict(),\\n      \\'optimizer_state_dict\\': optimizer.state_dict(),\\n      \\'avg_train_loss\\': avg_train_loss,\\n      }, f\\'./checkpoint_{epoch_i+1}.pt\\')\\n\\nprint(\"Training complete!\")\\n\\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "total_t0 = time.time() \n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    ## =================== Training =================== ##\n",
        "    avg_train_accuracy, avg_train_loss, training_time = training(train_dataloader, model)\n",
        "        \n",
        "    ## =================== Validation =================== ##\n",
        "    avg_val_accuracy, avg_val_loss, validation_time = validating(validation_dataloader, model)\n",
        "    \n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Training Accur.': avg_train_accuracy,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time,\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    #save model\n",
        "torch.save({\n",
        "      'epoch': epoch_i+1,\n",
        "      'model_state_dict': model.state_dict(),\n",
        "      'optimizer_state_dict': optimizer.state_dict(),\n",
        "      'avg_train_loss': avg_train_loss,\n",
        "      }, f'./checkpoint_{epoch_i+1}.pt')\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis and visualizations\n",
        "code for visualizing attention and other things in analysis-bertviz.ipnyb"
      ],
      "metadata": {
        "id": "OHXct-7RX5OM"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "212b508689a64a599a92941999c77105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3aa5043b136545ec82f1404e6c00c499",
              "IPY_MODEL_be8ce9b6d0994e73a84a6086d8a3f991",
              "IPY_MODEL_7c0761be0674443a9056f38eea06e9b4"
            ],
            "layout": "IPY_MODEL_bcc84f2b863d45268937c65e75cfcf1d"
          }
        },
        "3aa5043b136545ec82f1404e6c00c499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f388cfa85e84b2c85fa85c5970ccc50",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_91e97afea50f4a00a2254c7440f72de4",
            "value": "Downloading: 100%"
          }
        },
        "be8ce9b6d0994e73a84a6086d8a3f991": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db62856ce55474f921deb4fb26bf032",
            "max": 558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31c04396a79f4a76b1b3f7a4ae5a49ca",
            "value": 558
          }
        },
        "7c0761be0674443a9056f38eea06e9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6133a00a4e6b47e1ac773dd5f2713558",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b4ec17e6b954467f9da013ca6b6c574f",
            "value": " 558/558 [00:00&lt;00:00, 12.8kB/s]"
          }
        },
        "bcc84f2b863d45268937c65e75cfcf1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f388cfa85e84b2c85fa85c5970ccc50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e97afea50f4a00a2254c7440f72de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4db62856ce55474f921deb4fb26bf032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31c04396a79f4a76b1b3f7a4ae5a49ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6133a00a4e6b47e1ac773dd5f2713558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ec17e6b954467f9da013ca6b6c574f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d7b2c977c642ffa73faf05c8174246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_884cbdcd05f240cdb768dbe9fbab5e36",
              "IPY_MODEL_f16a0583627b4c6ea422514296428f17",
              "IPY_MODEL_39160144849c4a98a825eb698f63d145"
            ],
            "layout": "IPY_MODEL_bf7b57bcdf0b404fa79d4d2e344c9769"
          }
        },
        "884cbdcd05f240cdb768dbe9fbab5e36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_448b5aa17256467e8bffbbe2d74479a1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2acbe1af1276422ca85312531ed9c07e",
            "value": "Downloading: 100%"
          }
        },
        "f16a0583627b4c6ea422514296428f17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4991558fc0184d0084008f6a1bf4ba3d",
            "max": 843438,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c58f6be0e8247839b540ac3a4177747",
            "value": 843438
          }
        },
        "39160144849c4a98a825eb698f63d145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c6b11bf83943bc8c90ed3b86b3c4e1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c667f575d4064a7997f43c98298491bf",
            "value": " 824k/824k [00:00&lt;00:00, 1.41MB/s]"
          }
        },
        "bf7b57bcdf0b404fa79d4d2e344c9769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "448b5aa17256467e8bffbbe2d74479a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2acbe1af1276422ca85312531ed9c07e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4991558fc0184d0084008f6a1bf4ba3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c58f6be0e8247839b540ac3a4177747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c6b11bf83943bc8c90ed3b86b3c4e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c667f575d4064a7997f43c98298491bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eb002759658459fb9a2b892c1d7faf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff1d891d6b4641fcab1cf1ad441e6756",
              "IPY_MODEL_8ba157ac6fb2449b9d49fd477af80e6d",
              "IPY_MODEL_43f3573b30144c949755d57dad812d54"
            ],
            "layout": "IPY_MODEL_b0c5a573297541c49deb697de0d96c4c"
          }
        },
        "ff1d891d6b4641fcab1cf1ad441e6756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9550b6eef4e14364b19aeeda1c011881",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2f7de119890a46c489400a6b7dcd1698",
            "value": "Downloading: 100%"
          }
        },
        "8ba157ac6fb2449b9d49fd477af80e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1acdc8f5c56044f5ac7722dcc087b28c",
            "max": 1078931,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8f8dd58b7a44c4f8d4eb287a0de88c8",
            "value": 1078931
          }
        },
        "43f3573b30144c949755d57dad812d54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f4409c4d5474720a7d3f26168acf87c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0ebe993975884742b510817c236cbc5d",
            "value": " 1.03M/1.03M [00:00&lt;00:00, 1.01MB/s]"
          }
        },
        "b0c5a573297541c49deb697de0d96c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9550b6eef4e14364b19aeeda1c011881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f7de119890a46c489400a6b7dcd1698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1acdc8f5c56044f5ac7722dcc087b28c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f8dd58b7a44c4f8d4eb287a0de88c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f4409c4d5474720a7d3f26168acf87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebe993975884742b510817c236cbc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4147b6dfab1b4aa1ad347f1861be2cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdccf6ee1aee482e8f7e84dc128ccdc5",
              "IPY_MODEL_f574c001f4784d5da0c827cfa9882578",
              "IPY_MODEL_3ade69600e0440a0b2544234f7bdd54f"
            ],
            "layout": "IPY_MODEL_a5d53803cdf8414f930f80dbb4c012a3"
          }
        },
        "cdccf6ee1aee482e8f7e84dc128ccdc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2741349cf89a4778a5e9330c27e95299",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_91a808ac69404806b3708ca4e93dcf45",
            "value": "Downloading: 100%"
          }
        },
        "f574c001f4784d5da0c827cfa9882578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c82c16b68684f6eae6a0e97d950e26d",
            "max": 542529064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cab65a29d672448881a6e3026e457713",
            "value": 542529064
          }
        },
        "3ade69600e0440a0b2544234f7bdd54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a0a8839c76423ea6b82eae16dd16ae",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2f745a199bce43a4af95be9bd72622b1",
            "value": " 517M/517M [00:14&lt;00:00, 38.5MB/s]"
          }
        },
        "a5d53803cdf8414f930f80dbb4c012a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2741349cf89a4778a5e9330c27e95299": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a808ac69404806b3708ca4e93dcf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c82c16b68684f6eae6a0e97d950e26d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cab65a29d672448881a6e3026e457713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8a0a8839c76423ea6b82eae16dd16ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f745a199bce43a4af95be9bd72622b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}